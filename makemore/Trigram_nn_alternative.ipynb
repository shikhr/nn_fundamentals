{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fa841815-161e-46fe-9c19-253a103576b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "99dbad69-69ce-4cb6-b21f-bdbf9133f0d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = open(\"names.txt\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "28b68e0f-96eb-4371-9d81-a7c3878bc244",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = ['.'] + sorted(list(set(''.join(words))))\n",
    "stoi = {s: i for i, s in enumerate(chars)}\n",
    "itos = {i: s for s, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39f63de-49c8-4cb8-b4e6-e3ac9005d865",
   "metadata": {},
   "source": [
    "## Count Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3c103657-4566-45e1-8efd-431b057b8dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27, 27, 27), dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f313516-cfff-4af5-9a1e-442474de2189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b670ca58-a41d-45fb-8778-351ba5616ef1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculating counts of trigrams\n",
    "for w in words[:]:\n",
    "    w = ['.'] + list(w) + ['.']\n",
    "    for i in range(len(w)-2):\n",
    "        a, b, c = w[i], w[i+1], w[i+2]\n",
    "        N[stoi[a], stoi[b], stoi[c]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "952433c0-50f4-441b-84e2-bbde080b3e43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# probabilites from counts\n",
    "P = (N+1).float()\n",
    "P /= P.sum(2,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b346d-eab5-41fd-b464-40767025b66e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6643af1e-5e25-41e2-8e97-0c1f948a8f58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bigram probabilites, helpful in generating the first two tokens for sampling\n",
    "B = N.sum(2, keepdim=True).float()\n",
    "B = B/B.sum(1, keepdim=True)\n",
    "B = B.reshape((27,27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4438ee84-10bc-4695-9540-c34dbf642646",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3941b436-a5db-4845-a4ed-28126ee4768f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jisone.\n",
      "andeolla.\n",
      "aurpmcvtson.\n",
      "ma.\n",
      "trius.\n",
      "ruingolden.\n",
      "mell.\n",
      "vion.\n",
      "jaxfiq.\n",
      "kaygvyon.\n"
     ]
    }
   ],
   "source": [
    "# generating from the trigram model\n",
    "for i in range(10):\n",
    "    ix1 = 0\n",
    "    ix2 = torch.multinomial(B[ix1], num_samples=1, replacement=True).item()\n",
    "    outputs = [itos[ix2]]\n",
    "    while True:\n",
    "        p = P[ix1, ix2]\n",
    "        x = torch.multinomial(p, num_samples=1, replacement=True).item()\n",
    "        outputs.append(itos[x])\n",
    "        ix1 = ix2\n",
    "        ix2 = x\n",
    "        if x == 0:\n",
    "            break\n",
    "    print(''.join(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7612db66-ea81-4e51-b161-07e8f524ebb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.092747449874878\n"
     ]
    }
   ],
   "source": [
    "# evaluating loss \n",
    "nll = 0.0\n",
    "cnt = 0.0\n",
    "for w in words[:]:\n",
    "    w = ['.'] + list(w) + ['.']\n",
    "    for i in range(len(w)-2):\n",
    "        a, b, c = w[i], w[i+1], w[i+2]\n",
    "        prob = P[stoi[a], stoi[b], stoi[c]]\n",
    "        cnt+=1\n",
    "        logprob = torch.log(prob)\n",
    "        nll += logprob\n",
    "        # print(f'{a} {b} {c} : {prob.item():.4f} {logprob.item():.4f}')\n",
    "nll = -nll/cnt\n",
    "print(nll.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ebf9f1-e61e-4f29-a03c-a8f876a3fec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77c2cd49-d76e-4119-aa29-94b57d04a33f",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1a1ff655-bbc1-4b08-a8a0-49e7601f402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return index of (a,b) by flattening it \n",
    "ctx = 27\n",
    "def get_idx(a,b):\n",
    "    return ctx * a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "881188c7-6d2e-465c-9986-4ec6120851d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for w in words[:]:\n",
    "    w = ['.'] + list(w) + ['.']\n",
    "    for i in range(len(w)-2):\n",
    "        a, b, c = w[i], w[i+1], w[i+2]\n",
    "        xs.append(get_idx(stoi[a],stoi[b]))\n",
    "        ys.append(stoi[c])\n",
    "        \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2399aa6a-a5b2-4186-8f87-20705e771b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196113"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoded vectors \n",
    "xenc = F.one_hot(xs, num_classes=27*27).float()\n",
    "nums = xenc.shape[0]\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1b5bd039-0a3c-4f44-a737-3852f5683855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one layer model\n",
    "model = nn.Linear(729, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6fc030c3-ddb0-4dc9-9e6d-6fed64271739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lossfn for calculating loss and optimizer for upadting gradient\n",
    "lossfn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c46004cc-0f48-42ed-b62b-e83935aedd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 3.2908\n",
      "train: 2.5307\n",
      "train: 2.2431\n",
      "train: 2.1438\n",
      "train: 2.1074\n",
      "train: 2.0916\n",
      "train: 2.0832\n",
      "train: 2.0785\n",
      "train: 2.0755\n",
      "train: 2.0734\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "epochs = 100\n",
    "epfact = epochs/10\n",
    "for i in range(epochs):\n",
    "    y = model(xenc)\n",
    "    \n",
    "    loss = lossfn(y, ys)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % epfact == 0:\n",
    "        print(f'train: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc93d03-c1fc-4caf-914c-29e6cc1185a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "603cbc3b-bf90-4c69-984e-aa46b1280881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zykubia.\n",
      "jamyahrykieleni.\n",
      "jian.\n",
      "zir.\n",
      "dhvian.\n",
      "adarzah.\n",
      "zajamelleah.\n",
      "hayvie.\n",
      "sama.\n",
      "masser.\n"
     ]
    }
   ],
   "source": [
    "# generate\n",
    "for i in range(10):\n",
    "    ix1 = 0\n",
    "    ix2 = torch.multinomial(B[ix1], num_samples=1, replacement=True).item()\n",
    "    outputs = [itos[ix2]]\n",
    "    while True:\n",
    "        d = torch.tensor(get_index(ix1,ix2))\n",
    "        xen  = F.one_hot(d, num_classes=27*27).float()\n",
    "        y = model(xen)\n",
    "        p = torch.softmax(y,0)\n",
    "        x = torch.multinomial(p, num_samples=1, replacement=True).item()\n",
    "        outputs.append(itos[x])\n",
    "        ix1 = ix2\n",
    "        ix2 = x\n",
    "        if x == 0:\n",
    "            break\n",
    "    print(''.join(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b076a3-04b8-4fd3-85bb-18d1d85b39b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47185a9-4132-4ec9-a592-fa9bfaa7d9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fe0c80-a555-434f-88bd-2626530dd8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
