{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa841815-161e-46fe-9c19-253a103576b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99dbad69-69ce-4cb6-b21f-bdbf9133f0d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = open(\"names.txt\").read().splitlines()\n",
    "random.seed(42)\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28b68e0f-96eb-4371-9d81-a7c3878bc244",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = ['.'] + sorted(list(set(''.join(words))))\n",
    "stoi = {s: i for i, s in enumerate(chars)}\n",
    "itos = {i: s for s, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac4359c1-1ef0-47f6-95c6-a0c48ebfbd6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nsize = len(words)\n",
    "tsize = int(0.8*nsize)\n",
    "trainset = words[:tsize]\n",
    "testset = words[tsize:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b12b99b-156f-4ce6-86d4-8d46281af8ed",
   "metadata": {},
   "source": [
    "## Count Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89577c55-eedd-4122-bf95-e51e240a5529",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27, 27, 27), dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1f18aa-eac0-499c-91cf-1da568b680f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0316d406-3635-4b73-85d3-af13c8637a03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculating counts of trigrams\n",
    "for w in trainset[:]:\n",
    "    w = ['.'] + list(w) + ['.']\n",
    "    for i in range(len(w)-2):\n",
    "        a, b, c = w[i], w[i+1], w[i+2]\n",
    "        N[stoi[a], stoi[b], stoi[c]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de8fc7e2-94e1-4abe-8b9b-2409abc99fd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# probabilites from counts\n",
    "P = (N+1).float()\n",
    "P /= P.sum(2,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ee7a1f-b8e4-42f5-8717-a6281a1df8e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06bd5d9d-26ba-455f-9fe7-5d38718b8a2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bigram probabilites, helpful in generating the first two tokens for sampling\n",
    "B = N.sum(2, keepdim=True).float()\n",
    "B = B/B.sum(1, keepdim=True)\n",
    "B = B.reshape((27,27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ebf9f1-e61e-4f29-a03c-a8f876a3fec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ebdf5fd-78f3-4324-8916-9062b43ceb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dasid.\n",
      "ardene.\n",
      "luwaynn.\n",
      "lanid.\n",
      "cansona.\n",
      "layaria.\n",
      "formarmiah.\n",
      "xfj.\n",
      "cassaj.\n",
      "omne.\n"
     ]
    }
   ],
   "source": [
    "# generating from the trigram model\n",
    "for i in range(10):\n",
    "    ix1 = 0\n",
    "    ix2 = torch.multinomial(B[ix1], num_samples=1, replacement=True).item()\n",
    "    outputs = [itos[ix2]]\n",
    "    while True:\n",
    "        p = P[ix1, ix2]\n",
    "        x = torch.multinomial(p, num_samples=1, replacement=True).item()\n",
    "        outputs.append(itos[x])\n",
    "        ix1 = ix2\n",
    "        ix2 = x\n",
    "        if x == 0:\n",
    "            break\n",
    "    print(''.join(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03d4ef3c-b0d4-497f-bec7-ecdea01779ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0966954231262207\n"
     ]
    }
   ],
   "source": [
    "# evaluating loss on trainset\n",
    "nll = 0.0\n",
    "cnt = 0.0\n",
    "for w in trainset[:]:\n",
    "    w = ['.'] + list(w) + ['.']\n",
    "    for i in range(len(w)-2):\n",
    "        a, b, c = w[i], w[i+1], w[i+2]\n",
    "        prob = P[stoi[a], stoi[b], stoi[c]]\n",
    "        cnt+=1\n",
    "        logprob = torch.log(prob)\n",
    "        nll += logprob\n",
    "        # print(f'{a} {b} {c} : {prob.item():.4f} {logprob.item():.4f}')\n",
    "nll = -nll/cnt\n",
    "print(nll.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e7abb00-bf7c-43f1-815b-48b92f2d40a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12101674079895\n"
     ]
    }
   ],
   "source": [
    "# evaluating loss on testset\n",
    "nll = 0.0\n",
    "cnt = 0.0\n",
    "for w in testset[:]:\n",
    "    w = ['.'] + list(w) + ['.']\n",
    "    for i in range(len(w)-2):\n",
    "        a, b, c = w[i], w[i+1], w[i+2]\n",
    "        prob = P[stoi[a], stoi[b], stoi[c]]\n",
    "        cnt+=1\n",
    "        logprob = torch.log(prob)\n",
    "        nll += logprob\n",
    "        # print(f'{a} {b} {c} : {prob.item():.4f} {logprob.item():.4f}')\n",
    "nll = -nll/cnt\n",
    "print(nll.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c2cd49-d76e-4119-aa29-94b57d04a33f",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "881188c7-6d2e-465c-9986-4ec6120851d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "xst = []\n",
    "yst = []\n",
    "\n",
    "for w in trainset[:]:\n",
    "    w = ['.'] + list(w) + ['.']\n",
    "    for i in range(len(w)-2):\n",
    "        a, b, c = w[i], w[i+1], w[i+2]\n",
    "        xs.append([stoi[a], stoi[b]])\n",
    "        ys.append(stoi[c])\n",
    "\n",
    "for w in testset[:]:\n",
    "    w = ['.'] + list(w) + ['.']\n",
    "    for i in range(len(w)-2):\n",
    "        a, b, c = w[i], w[i+1], w[i+2]\n",
    "        xst.append([stoi[a], stoi[b]])\n",
    "        yst.append(stoi[c])\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "xst = torch.tensor(xst)\n",
    "yst = torch.tensor(yst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2399aa6a-a5b2-4186-8f87-20705e771b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking one hot encoded vectors train\n",
    "a1 = F.one_hot(xs[:,0], num_classes=27)\n",
    "a2 = F.one_hot(xs[:,1], num_classes=27)\n",
    "xenc = torch.hstack((a1,a2)).float()\n",
    "nums = xenc.shape[0]\n",
    "\n",
    "# stacking one hot encoded vectors test \n",
    "b1 = F.one_hot(xst[:,0], num_classes=27)\n",
    "b2 = F.one_hot(xst[:,1], num_classes=27)\n",
    "xenct = torch.hstack((b1,b2)).float()\n",
    "nums = xenc.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b5bd039-0a3c-4f44-a737-3852f5683855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one layer model\n",
    "model = nn.Linear(54, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6fc030c3-ddb0-4dc9-9e6d-6fed64271739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lossfn for calculating loss and optimizer for upadting gradient\n",
    "lossfn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c46004cc-0f48-42ed-b62b-e83935aedd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 3.3325 || test: 3.1860\n",
      "train: 2.2534 || test: 2.2545\n",
      "train: 2.2409 || test: 2.2429\n",
      "train: 2.2386 || test: 2.2411\n",
      "train: 2.2378 || test: 2.2405\n",
      "train: 2.2373 || test: 2.2403\n",
      "train: 2.2371 || test: 2.2402\n",
      "train: 2.2369 || test: 2.2402\n",
      "train: 2.2368 || test: 2.2402\n",
      "train: 2.2368 || test: 2.2402\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "epochs = 500\n",
    "epfact = epochs/10\n",
    "for i in range(epochs):\n",
    "    # train\n",
    "    y = model(xenc)\n",
    "    \n",
    "    loss = lossfn(y, ys)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # test\n",
    "    yt = model(xenct)\n",
    "    losst = lossfn(yt, yst)\n",
    "    \n",
    "    if i % epfact == 0:\n",
    "        print(f'train: {loss.item():.4f} || test: {losst.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc93d03-c1fc-4caf-914c-29e6cc1185a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "603cbc3b-bf90-4c69-984e-aa46b1280881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ka.\n",
      "amiven.\n",
      "merona.\n",
      "erh.\n",
      "jechanyon.\n",
      "lynnntaleydonjamirestaeriosepon.\n",
      "dish.\n",
      "beylayah.\n",
      "peakhryanzyph.\n",
      "mber.\n"
     ]
    }
   ],
   "source": [
    "# generate\n",
    "for i in range(10):\n",
    "    ix1 = 0\n",
    "    ix2 = torch.multinomial(B[ix1], num_samples=1, replacement=True).item()\n",
    "    outputs = [itos[ix2]]\n",
    "    while True:\n",
    "        x1 = F.one_hot(torch.tensor(ix1), num_classes=27)\n",
    "        x2 = F.one_hot(torch.tensor(ix2), num_classes=27)\n",
    "        xen = torch.hstack((x1,x2)).float()\n",
    "        y = model(xen)\n",
    "        p = torch.softmax(y,0)\n",
    "        x = torch.multinomial(p, num_samples=1, replacement=True).item()\n",
    "        outputs.append(itos[x])\n",
    "        ix1 = ix2\n",
    "        ix2 = x\n",
    "        if x == 0:\n",
    "            break\n",
    "    print(''.join(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b076a3-04b8-4fd3-85bb-18d1d85b39b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47185a9-4132-4ec9-a592-fa9bfaa7d9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
