{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-06T16:23:09.283239Z","iopub.execute_input":"2024-06-06T16:23:09.283530Z","iopub.status.idle":"2024-06-06T16:23:10.241677Z","shell.execute_reply.started":"2024-06-06T16:23:09.283505Z","shell.execute_reply":"2024-06-06T16:23:10.240749Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\n\n! wget \"https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\"","metadata":{"execution":{"iopub.status.busy":"2024-06-06T16:23:10.243314Z","iopub.execute_input":"2024-06-06T16:23:10.243661Z","iopub.status.idle":"2024-06-06T16:23:15.081940Z","shell.execute_reply.started":"2024-06-06T16:23:10.243638Z","shell.execute_reply":"2024-06-06T16:23:15.080657Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"--2024-06-06 16:23:14--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 228145 (223K) [text/plain]\nSaving to: 'names.txt'\n\nnames.txt           100%[===================>] 222.80K  --.-KB/s    in 0.01s   \n\n2024-06-06 16:23:14 (17.9 MB/s) - 'names.txt' saved [228145/228145]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"words = open('/kaggle/working/names.txt').read().splitlines()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T16:23:15.083498Z","iopub.execute_input":"2024-06-06T16:23:15.084135Z","iopub.status.idle":"2024-06-06T16:23:15.092100Z","shell.execute_reply.started":"2024-06-06T16:23:15.084104Z","shell.execute_reply":"2024-06-06T16:23:15.091277Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-06-06T16:23:15.094849Z","iopub.execute_input":"2024-06-06T16:23:15.095377Z","iopub.status.idle":"2024-06-06T16:23:15.152808Z","shell.execute_reply.started":"2024-06-06T16:23:15.095350Z","shell.execute_reply":"2024-06-06T16:23:15.151882Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"# build the vocabulary of characters and mappings to/from integers\nchars = sorted(list(set(''.join(words))))\nstoi = {s:i+2 for i,s in enumerate(chars)}\nstoi['.'] = 0\nstoi['_'] = 1\nitos = {i:s for s,i in stoi.items()}\n# print(itos)\nn_vocab = len(stoi)\n\nmax_len = len(max(words, key=len))+1","metadata":{"execution":{"iopub.status.busy":"2024-06-06T16:23:15.153977Z","iopub.execute_input":"2024-06-06T16:23:15.154954Z","iopub.status.idle":"2024-06-06T16:23:15.166053Z","shell.execute_reply.started":"2024-06-06T16:23:15.154927Z","shell.execute_reply":"2024-06-06T16:23:15.165248Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def build_dataset(words):\n    X = []\n    Y = []\n    for word in words:\n        word = '.' + word + '_'\n        ints = [stoi[ch] for ch in list(word)]\n        xi = ints[:-1]\n        yi = ints[1:]\n        xi.extend([0]*(max_len-len(xi)))\n        yi.extend([-1]*(max_len-len(yi)))\n        X.append(xi)\n        Y.append(yi)\n    return torch.tensor(X), torch.tensor(Y)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-06T16:23:15.167108Z","iopub.execute_input":"2024-06-06T16:23:15.167388Z","iopub.status.idle":"2024-06-06T16:23:15.175401Z","shell.execute_reply.started":"2024-06-06T16:23:15.167365Z","shell.execute_reply":"2024-06-06T16:23:15.174481Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"Xtr, Ytr = build_dataset(words)\nXtr.shape, Ytr.shape\nXtr = Xtr.to(device)\nYtr = Ytr.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T16:23:15.176530Z","iopub.execute_input":"2024-06-06T16:23:15.177039Z","iopub.status.idle":"2024-06-06T16:23:15.863574Z","shell.execute_reply.started":"2024-06-06T16:23:15.177014Z","shell.execute_reply":"2024-06-06T16:23:15.862766Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad\ndef print_names(times, model):\n    model.eval()\n    for i in range(times):\n        res = []\n        with torch.no_grad():\n            inp = torch.tensor([[0]]);\n            inp = inp.to(device)\n            while True:\n                oi,_ = model(inp)\n                pred = oi[:,-1,:]\n                p = torch.softmax(pred,1).squeeze()\n                out = torch.multinomial(p, 1, True)\n                inp = torch.cat((inp, out[:,None]),1)\n                if out == 1: break\n\n                res.append(itos[out.item()])\n        print(''.join(res))","metadata":{"execution":{"iopub.status.busy":"2024-06-06T16:23:15.864684Z","iopub.execute_input":"2024-06-06T16:23:15.864982Z","iopub.status.idle":"2024-06-06T16:23:15.872374Z","shell.execute_reply.started":"2024-06-06T16:23:15.864957Z","shell.execute_reply":"2024-06-06T16:23:15.871437Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RNN","metadata":{}},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self, n_vocab, n_embed, n_hidden):\n        super().__init__()\n        self.n_embed = n_embed\n        self.n_vocab = n_vocab\n        self.n_hidden = n_hidden\n        self.emb = nn.Embedding(n_vocab, n_embed) # embedding\n        self.linX = nn.Linear(n_embed, n_hidden,) # weights for x\n        self.linH = nn.Linear(n_hidden, n_hidden) # weights for prev hidden\n        self.linO = nn.Linear(n_hidden, n_vocab) # weight for output\n        self.start = nn.Parameter(torch.zeros(1, n_hidden))  # learnable initial state\n        \n    def forward(self, x, y=None):\n        bs, t = x.shape\n        hidden = []\n        h_prev = self.start.expand((bs, -1)) # (bs, n_hidden)\n        loss = None\n        embs = self.emb(x) # precomputing embedding for performance (bs, T, n_embed)\n        for i in range(t): # looping over time (sequence)\n            xi = embs[:, i, :] # extracting a slice of time (bs, 1, n_embed)\n            hi = torch.tanh(self.linX(xi) + self.linH(h_prev)) # rnn equation (bs, 1, n_hidden)\n            h_prev = hi # making current state as prev state\n            hidden.append(hi) # saving current_state\n        \n        hidden = torch.stack(hidden,1) # merging all hidden state slices together (bs, T, n_hidden) \n        logits = self.linO(hidden) # projecting to vocab size (bs, T, n_vocab)\n        \n        # unfolding all time step across the batches into (bs*T, n_vocab) and target into (bs*t, 1) for cross entropy\n        if self.training:\n            loss = F.cross_entropy(logits.view(-1, self.n_vocab), y.view(-1), ignore_index=-1)\n        \n        return logits, loss\n","metadata":{"execution":{"iopub.status.busy":"2024-06-06T16:25:17.642944Z","iopub.execute_input":"2024-06-06T16:25:17.643323Z","iopub.status.idle":"2024-06-06T16:25:17.653555Z","shell.execute_reply.started":"2024-06-06T16:25:17.643294Z","shell.execute_reply":"2024-06-06T16:25:17.652687Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"n_embed = 164\nn_hidden = 256\nblock_size = 32","metadata":{"execution":{"iopub.status.busy":"2024-06-06T16:25:18.108987Z","iopub.execute_input":"2024-06-06T16:25:18.109288Z","iopub.status.idle":"2024-06-06T16:25:18.113245Z","shell.execute_reply.started":"2024-06-06T16:25:18.109263Z","shell.execute_reply":"2024-06-06T16:25:18.112371Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model = RNN(n_vocab, n_embed, n_hidden)\nmodel.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T16:25:18.445323Z","iopub.execute_input":"2024-06-06T16:25:18.445603Z","iopub.status.idle":"2024-06-06T16:25:18.453340Z","shell.execute_reply.started":"2024-06-06T16:25:18.445580Z","shell.execute_reply":"2024-06-06T16:25:18.452475Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"traindl = DataLoader(TensorDataset(Xtr, Ytr), block_size, True)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T16:25:19.989278Z","iopub.execute_input":"2024-06-06T16:25:19.989994Z","iopub.status.idle":"2024-06-06T16:25:19.994029Z","shell.execute_reply.started":"2024-06-06T16:25:19.989964Z","shell.execute_reply":"2024-06-06T16:25:19.993158Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"epochs = 10\ni = 0\nfor epoch in range(epochs):\n    model.train()\n    for xi, yi in traindl:\n        logits, loss = model(xi, yi)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if i % 1500 == 0:\n            print(f'{epoch}:{i} || loss: {loss.item():.4f}')\n        i+=1","metadata":{"execution":{"iopub.status.busy":"2024-06-06T16:25:26.587275Z","iopub.execute_input":"2024-06-06T16:25:26.588030Z","iopub.status.idle":"2024-06-06T16:26:46.751429Z","shell.execute_reply.started":"2024-06-06T16:25:26.587998Z","shell.execute_reply":"2024-06-06T16:26:46.750457Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"0:0 || loss: 3.4175\n1:1500 || loss: 2.4336\n2:3000 || loss: 2.1803\n4:4500 || loss: 2.5107\n5:6000 || loss: 2.2769\n7:7500 || loss: 2.3809\n8:9000 || loss: 2.2709\n","output_type":"stream"}]},{"cell_type":"code","source":"print_names(10, model)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T16:29:36.357846Z","iopub.execute_input":"2024-06-06T16:29:36.358598Z","iopub.status.idle":"2024-06-06T16:29:36.422258Z","shell.execute_reply.started":"2024-06-06T16:29:36.358569Z","shell.execute_reply":"2024-06-06T16:29:36.421409Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"rayden\nleormen\nraelon\nehriyah\nlanim\nsiyah\nlluwyn\nedmell\nrhmiree\nkaizlee\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}