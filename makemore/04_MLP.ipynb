{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "59d31940-a154-42be-9cc7-5e65564a41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4467aaa7-287e-4f92-aa02-0a33bc2ffaea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "33b15b7c-6a5d-4654-818c-20b4ac5be43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9f64401d-ed90-44e1-89f0-622cdbc0dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars =  ['.'] + sorted(list(set(''.join(words)))) \n",
    "stoi = {s: i for i, s in enumerate(chars)}\n",
    "itos = {i: s for s, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8af0f9d8-5164-47b7-bc37-474a2f9226e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "context_size = 3\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        # print(w)\n",
    "        context = [0]*context_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            # print(''.join(itos[i] for i in context), '-->', itos[ix])\n",
    "            context = context[1:]+[ix]\n",
    "        \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c6173c00-9cab-40e7-98eb-eb11046617f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([182625, 3]), torch.Size([182625]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.shape, Ytr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "260141de-bf3a-43a5-83c8-9d3da51caf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 16\n",
    "C = torch.randn((27,emb_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7341e840-46b1-4a7f-ade1-60b39347e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb = C[X]\n",
    "# emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df197fd8-7ded-48c0-9762-4462db5dc581",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Flatten input tensor\n",
    "we flatten input tensor because a 2d tensor of context_size * embed_dim needs to flattened so it can be inputted to the neural network which only takes a 1d tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5986e9ac-6e6d-4295-99ee-2a5c9527fb01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Different ways to flatten\n",
    "# torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], 1)  # not flexible\n",
    "# torch.cat(torch.unbind(emb, 1),1).shape  # flexible but not efficient\n",
    "# emb.reshape((32,-1))  # efficient but may or may not return a copy\n",
    "# emb_out = emb.view(emb.shape[0], -1) # does not create a copy but needs tensor to be contiguous!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0475bdf6-7a3f-4f10-95ac-37f8f825a450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_size*emb_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5d52bd90-7a6a-4947-8e1e-94af534b2331",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((context_size*emb_dim, 200))\n",
    "b1 = torch.randn(200)\n",
    "W2 = torch.randn((200, 27))\n",
    "b2 = torch.randn(27)\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5e82d415-716f-47d3-865a-e68d6fde67bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15659"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3fe19c04-6074-4994-b211-76120dbf16f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200000\n",
    "et = epochs/10\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "58b6a556-5375-496e-9d13-0e05f84e6d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossi=[]\n",
    "stepi=[]\n",
    "ep = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "32e415a9-8396-4b45-b108-51d73307a7b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    # mini batch\n",
    "    ix = torch.randint(0,Xtr.shape[0],(48,))\n",
    "\n",
    "    #forward \n",
    "    emb = C[Xtr[ix]]\n",
    "    emb_out = emb.view(emb.shape[0], -1)\n",
    "    h = torch.tanh(emb_out @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Ytr[ix])\n",
    "\n",
    "    if i > 100000:\n",
    "        lr = 0.01\n",
    "    # backward\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    for p in parameters:\n",
    "        p.data += -lr*p.grad\n",
    "\n",
    "    stepi.append(ep)\n",
    "    lossi.append(loss.log10().item())\n",
    "    ep+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7c9fcdc9-af89-4919-97c5-ecb9a258f3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.14638352394104"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dev loss\n",
    "emb = C[Xdev]\n",
    "emb_out = emb.view(emb.shape[0], -1)\n",
    "h = torch.tanh(emb_out @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Ydev)\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4cbb6f62-d01d-4288-8470-60b2ca908c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0744006633758545"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train loss\n",
    "emb = C[Xtr]\n",
    "emb_out = emb.view(emb.shape[0], -1)\n",
    "h = torch.tanh(emb_out @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Ytr)\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d0e44007-0a7e-4046-8784-5aaad5f0fd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.142019510269165"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test loss\n",
    "emb = C[Xte]\n",
    "emb_out = emb.view(emb.shape[0], -1)\n",
    "h = torch.tanh(emb_out @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Yte)\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9c674f31-dcaa-4029-959f-ff83d6b2549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8,8))\n",
    "# plt.scatter(C[:,0].data, C[:,1].data, s=200)\n",
    "# for i in range(C.shape[0]):\n",
    "#     plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha=\"center\", va='center', color=\"white\")\n",
    "# plt.grid('minor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2710c430-adfc-4643-967d-9630231313b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "racler.\n",
      "kin.\n",
      "chendonn.\n",
      "tritty.\n",
      "corbea.\n",
      "keny.\n",
      "zyeadim.\n",
      "prin.\n",
      "keevy.\n",
      "zihance.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    context = [0]*context_size\n",
    "    output = []\n",
    "    while True:\n",
    "        emb = C[context]\n",
    "        ee = emb.view(1, -1)\n",
    "        h = torch.tanh(ee @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        p = torch.softmax(logits, 1)\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True).item()\n",
    "        output.append(itos[ix])\n",
    "        context = context[1:]+[ix]\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c935cc-70ad-4c48-ac65-56607cf1258a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
